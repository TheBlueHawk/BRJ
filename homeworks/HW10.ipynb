{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW10: Algorithmic Fairness \n",
    "\n",
    "### Note: to complete most of this homework notions from week 11 slides are needed\n",
    "\n",
    "In this homework you will assess racial bias in the COMPAS algorithm and judges decisions. \n",
    "\n",
    "The data is a collection of 7000 criminal cases in Florida in which COMPAS was used and it contains information about defendants' demographics, criminal history (e.g., juvenile criminal records), court decision and recidivism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings = lambda *a, **kw: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       7214 non-null   int64  \n",
      " 1   name                     7214 non-null   object \n",
      " 2   first                    7214 non-null   object \n",
      " 3   last                     7214 non-null   object \n",
      " 4   compas_screening_date    7214 non-null   object \n",
      " 5   sex                      7214 non-null   object \n",
      " 6   dob                      7214 non-null   object \n",
      " 7   age                      7214 non-null   int64  \n",
      " 8   age_cat                  7214 non-null   object \n",
      " 9   race                     7214 non-null   object \n",
      " 10  juv_fel_count            7214 non-null   int64  \n",
      " 11  decile_score             7214 non-null   int64  \n",
      " 12  juv_misd_count           7214 non-null   int64  \n",
      " 13  juv_other_count          7214 non-null   int64  \n",
      " 14  priors_count             7214 non-null   int64  \n",
      " 15  days_b_screening_arrest  6907 non-null   float64\n",
      " 16  c_jail_in                6907 non-null   object \n",
      " 17  c_jail_out               6907 non-null   object \n",
      " 18  c_case_number            7192 non-null   object \n",
      " 19  c_offense_date           6055 non-null   object \n",
      " 20  c_arrest_date            1137 non-null   object \n",
      " 21  c_days_from_compas       7192 non-null   float64\n",
      " 22  c_charge_degree          7214 non-null   object \n",
      " 23  c_charge_desc            7185 non-null   object \n",
      " 24  is_recid                 7214 non-null   int64  \n",
      " 25  r_case_number            3471 non-null   object \n",
      " 26  r_charge_degree          3471 non-null   object \n",
      " 27  r_days_from_arrest       2316 non-null   float64\n",
      " 28  r_offense_date           3471 non-null   object \n",
      " 29  r_charge_desc            3413 non-null   object \n",
      " 30  r_jail_in                2316 non-null   object \n",
      " 31  r_jail_out               2316 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         7214 non-null   int64  \n",
      " 34  vr_case_number           819 non-null    object \n",
      " 35  vr_charge_degree         819 non-null    object \n",
      " 36  vr_offense_date          819 non-null    object \n",
      " 37  vr_charge_desc           819 non-null    object \n",
      " 38  type_of_assessment       7214 non-null   object \n",
      " 39  decile_score.1           7214 non-null   int64  \n",
      " 40  score_text               7214 non-null   object \n",
      " 41  screening_date           7214 non-null   object \n",
      " 42  v_type_of_assessment     7214 non-null   object \n",
      " 43  v_decile_score           7214 non-null   int64  \n",
      " 44  v_score_text             7214 non-null   object \n",
      " 45  v_screening_date         7214 non-null   object \n",
      " 46  in_custody               6978 non-null   object \n",
      " 47  out_custody              6978 non-null   object \n",
      " 48  priors_count.1           7214 non-null   int64  \n",
      " 49  start                    7214 non-null   int64  \n",
      " 50  end                      7214 non-null   int64  \n",
      " 51  event                    7214 non-null   int64  \n",
      " 52  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_from_recid'] = pd.to_datetime(df['r_offense_date']) - pd.to_datetime(df['c_offense_date'])\n",
    "df['days_from_recid'] = df['days_from_recid'].dt.days\n",
    "df['two_year_recid2'] = (df['days_from_recid']<=730).astype(int)\n",
    "\n",
    "#generate felony charge dummies\n",
    "df['felony'] = (df['c_charge_degree'] == 'F').astype(int)\n",
    "\n",
    "#generate age dummies\n",
    "d = pd.get_dummies(df['age_cat'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df = df.rename(columns={'25 - 45':'age_cat_25 - 45', 'Greater than 45':'age_cat_Greater than 45', 'Less than 25':'age_cat_Less than 25'})\n",
    "\n",
    "#generate ethnicity, race and compas score dummies\n",
    "d = pd.get_dummies(df['race'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df['male'] = (df['sex'] == 'Male').astype(int)\n",
    "d = pd.get_dummies(df['score_text'])\n",
    "df = pd.concat([df, d], axis=1)\n",
    "df = df.rename(columns={'High':'score_text_high', 'Medium':'score_text_medium', 'Low':'score_text_low'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting outcomes and predictors\n",
    "\n",
    "The *ideal* target variable for the COMPAS algorithm is the presence of a recidivism episode, while for judges is the decision to send the defendant to jail. For the predictors we use some deomgraphic characteristics **excluding race**, criminal hisotry and type of crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4283\n",
       "1    2931\n",
       "Name: jailed, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# judge decision: \"jailed\" = more than one day in jail.\n",
    "df['jail_days'] = pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "df['jailed'] = (df.jail_days.dt.days > 1).astype(int)\n",
    "D = df['jailed']\n",
    "D.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4557\n",
       "1    2657\n",
       "Name: two_year_recid2, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithm outcome\n",
    "Y = df['two_year_recid2'] \n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>felony</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "      <td>7214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.646798</td>\n",
       "      <td>0.806626</td>\n",
       "      <td>34.817993</td>\n",
       "      <td>0.067230</td>\n",
       "      <td>0.090934</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>3.472415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477998</td>\n",
       "      <td>0.394971</td>\n",
       "      <td>11.888922</td>\n",
       "      <td>0.473972</td>\n",
       "      <td>0.485239</td>\n",
       "      <td>0.501586</td>\n",
       "      <td>4.882538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            felony         male          age  juv_fel_count  juv_misd_count  \\\n",
       "count  7214.000000  7214.000000  7214.000000    7214.000000     7214.000000   \n",
       "mean      0.646798     0.806626    34.817993       0.067230        0.090934   \n",
       "std       0.477998     0.394971    11.888922       0.473972        0.485239   \n",
       "min       0.000000     0.000000    18.000000       0.000000        0.000000   \n",
       "25%       0.000000     1.000000    25.000000       0.000000        0.000000   \n",
       "50%       1.000000     1.000000    31.000000       0.000000        0.000000   \n",
       "75%       1.000000     1.000000    42.000000       0.000000        0.000000   \n",
       "max       1.000000     1.000000    96.000000      20.000000       13.000000   \n",
       "\n",
       "       juv_other_count  priors_count  \n",
       "count      7214.000000   7214.000000  \n",
       "mean          0.109371      3.472415  \n",
       "std           0.501586      4.882538  \n",
       "min           0.000000      0.000000  \n",
       "25%           0.000000      0.000000  \n",
       "50%           0.000000      2.000000  \n",
       "75%           0.000000      5.000000  \n",
       "max          17.000000     38.000000  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictors\n",
    "predictors = ['felony',\n",
    "              'male', 'age', \n",
    "              'juv_fel_count','juv_misd_count', 'juv_other_count', 'priors_count']\n",
    "X = df[predictors]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                377\n",
       "Asian                 32\n",
       "Native American       18\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7214.000000\n",
       "mean        0.659828\n",
       "std         0.473800\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicator variable for non-white\n",
    "NW = (df['race'] != 'Caucasian').astype(int)\n",
    "NW.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Algorithm: Predict Recidivism from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following you will predict recidivism from defendants' features using a nested training/test split so we can get clean test-set predictions for the whole dataset (see the notebook and homework on double machine learning for how to do this - week 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform nested train/test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test, D_train, D_test,NW_train, NW_test = train_test_split(X, Y, D, NW, test_size = 0.5)\n",
    "\n",
    "df_pred = X_train.append(X_test) \n",
    "#TODO train a logit model to predict recidism (Y) from predictors (X).\n",
    "#TODO form clean test-set predictions for recidivism in the full dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "Y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6581646797892986\n",
      "balanced_accuracy_score:  0.5639855672847859\n",
      "roc_auc_score:  0.5639855672847859\n",
      "[[2094  192]\n",
      " [1041  280]]\n",
      "FP / FN =  0.1844380403458213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1844380403458213"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO show a confusion matrix, compute accuracy, balanced accuracy, and roc_auc\n",
    "#TODO compute ratio of false positives to false negatives\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (precision_score, confusion_matrix, recall_score, f1_score, precision_recall_curve,\n",
    "                             plot_confusion_matrix, accuracy_score, balanced_accuracy_score, roc_curve, auc, roc_auc_score)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model, X_test, Y_test)\n",
    "\n",
    "def report_stas(Y_test, Y_test_pred):\n",
    "    print(\"accuracy_score: \", accuracy_score(Y_test, Y_test_pred))\n",
    "    print(\"balanced_accuracy_score: \", balanced_accuracy_score(Y_test, Y_test_pred))\n",
    "    print(\"roc_auc_score: \", roc_auc_score(Y_test, Y_test_pred))\n",
    "\n",
    "    cm = confusion_matrix(Y_test, Y_test_pred)\n",
    "    print(cm)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    print(\"FP / FN = \", FP / FN)\n",
    "\n",
    "    return FP / FN\n",
    "\n",
    "report_stas(Y_test, Y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare treatment of whites and non-whites for recidivism prediction\n",
    "##### Refer to week 11 for these concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white_base_rate:  0.3211083944580277\n",
      "non_white_base_rate:  0.38949579831932774\n"
     ]
    }
   ],
   "source": [
    "##TODO Compare base rates for recidivism outcomes of whites and non-whites\n",
    "\n",
    "#df['male'] = (df['sex'] == 'Male').astype(int)\n",
    "#NW = (df['race'] != 'Caucasian').astype(int)\n",
    "#NW.rename(columns={'Not white'})\n",
    "df_race_recid = pd.DataFrame(NW_test)\n",
    "#df.rename(columns={'High':'score_text_high', 'Medium':'score_text_medium', 'Low':'score_text_low'})\n",
    "df_race_recid['recid'] = Y_test\n",
    "df_race_recid['recid_pred'] = Y_test_pred\n",
    "df_race_recid.head()\n",
    "\n",
    "\n",
    "white_recid = len(df_race_recid[(df_race_recid['race']==0) & (df_race_recid['recid']==1)])\n",
    "white_base_rate = white_recid / len(df_race_recid[(df_race_recid['race']==0)]) \n",
    "\n",
    "non_white_recid = len(df_race_recid[(df_race_recid['race']==1) & (df_race_recid['recid']==1)])\n",
    "non_white_base_rate =  non_white_recid / len(df_race_recid[(df_race_recid['race']==1)])\n",
    "\n",
    "print('white_base_rate: ', white_base_rate)\n",
    "print('non_white_base_rate: ', non_white_base_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE\n",
      "accuracy_score:  0.6837815810920945\n",
      "balanced_accuracy_score:  0.5377100078610124\n",
      "roc_auc_score:  0.5377100078610124\n",
      "[[788  45]\n",
      " [343  51]]\n",
      "FP / FN =  0.13119533527696792\n",
      "\n",
      "NON WHITE\n",
      "accuracy_score:  0.6449579831932774\n",
      "balanced_accuracy_score:  0.5729317240452554\n",
      "roc_auc_score:  0.5729317240452555\n",
      "[[1306  147]\n",
      " [ 698  229]]\n",
      "FP / FN =  0.21060171919770773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21060171919770773"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO Produce confusion matrices, classification reports, and ratio of false positives to false negatives, separately for whites and non-whites.\n",
    "print('WHITE')\n",
    "Y_test_white = df_race_recid[df_race_recid['race']==0]['recid']\n",
    "Y_test_pred_white = df_race_recid[df_race_recid['race']==0]['recid_pred']\n",
    "report_stas(Y_test_white, Y_test_pred_white)\n",
    "\n",
    "\n",
    "print('\\nNON WHITE')\n",
    "Y_test_white = df_race_recid[df_race_recid['race']==1]['recid']\n",
    "Y_test_pred_white = df_race_recid[df_race_recid['race']==1]['recid_pred']\n",
    "report_stas(Y_test_white, Y_test_pred_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What concepts of \"fairness\" (from class) are (approximately) satisfied by this classifier? Explain.**\n",
    "\n",
    "> Groups fairness is guaranteed if we take \"balanced_accuracy_score\" or \"roc_auc_score\" as a metric. \n",
    "However we can if we consider \"accuracy_score\" or \"FP / FN\" we see group discrimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Judges' Decisions: Predict Judge Decision from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following you will predict judges' decisions from defendants' features using a nested training/test split as before. In a second model, include Y-hat from previous section as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO train a logit model to predict judge decision (D) from predictors (X). \n",
    "# perform nested train/test split \n",
    "#X_train, X_test, Y_train, Y_test, D_train, D_test,NW_train, NW_test = train_test_split(X, Y, D, NW, test_size = 0.5)\n",
    "\n",
    "#TODO train a logit model to predict recidism (Y) from predictors (X).\n",
    "#TODO form clean test-set predictions for recidivism in the full dataset\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "model_D = LogisticRegression()\n",
    "model_D.fit(X_train, D_train)\n",
    "D_test_pred = model_D.predict(X_test)\n",
    "D_train_pred = model_D.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO train a logit model to predict judge decision (D) from predictors (X) and predicted recidivism risk (Yhat)\n",
    "#TODO form clean test-set predictions for the decisions in the full dataset\n",
    "X_train['y_pred'] = Y_train_pred\n",
    "X_test['y_pred'] = Y_test_pred\n",
    "Xy = X_train.append(X_test)\n",
    "\n",
    "model_D_with_y = LogisticRegression()\n",
    "model_D_with_y.fit(X_train, D_train)\n",
    "D_test_pred_with_y_pred = model_D_with_y.predict(X_test)\n",
    "D_train_pred_with_y_pred = model_D_with_y.predict(X_train)\n",
    "D_pred_with_y_pred = model_D_with_y.predict(Xy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare treatment of whites and non-whites for recidivism prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE wihtout Y_pred\n",
      "accuracy_score:  0.6487367563162184\n",
      "balanced_accuracy_score:  0.564899775528689\n",
      "roc_auc_score:  0.564899775528689\n",
      "[[698  60]\n",
      " [371  98]]\n",
      "FP / FN =  0.16172506738544473\n",
      "\n",
      "WHITE whit Y_pred\n",
      "accuracy_score:  0.6479217603911981\n",
      "balanced_accuracy_score:  0.5674918847151352\n",
      "roc_auc_score:  0.5674918847151352\n",
      "[[689  69]\n",
      " [363 106]]\n",
      "FP / FN =  0.19008264462809918\n",
      "\n",
      "NON WHITE wihtout Y_pred\n",
      "accuracy_score:  0.6197478991596639\n",
      "balanced_accuracy_score:  0.5710084921730265\n",
      "roc_auc_score:  0.5710084921730264\n",
      "[[1176  235]\n",
      " [ 670  299]]\n",
      "FP / FN =  0.35074626865671643\n",
      "\n",
      "NON WHITE whit Y_pred\n",
      "accuracy_score:  0.623109243697479\n",
      "balanced_accuracy_score:  0.5761062827160033\n",
      "roc_auc_score:  0.5761062827160033\n",
      "[[1170  241]\n",
      " [ 656  313]]\n",
      "FP / FN =  0.3673780487804878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3673780487804878"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO Produce confusion matrices, classification reports, and ratio of false positives to false negatives, \n",
    "##TODO separately for whites and non-whites, and with/without including Y-hat as a predictor.\n",
    "\n",
    "df_race_decision = pd.DataFrame(NW_test)\n",
    "df_race_decision['decision'] = D_test\n",
    "df_race_decision['decision_pred'] = D_test_pred\n",
    "df_race_decision['decision_pred_with_y_pred'] = D_test_pred_with_y_pred\n",
    "df_race_decision.head()\n",
    "\n",
    "\n",
    "D_test_white = df_race_decision[df_race_decision['race']==0]['decision']\n",
    "D_test_pred_white = df_race_decision[df_race_decision['race']==0]['decision_pred']\n",
    "D_test_pred_wy_white = df_race_decision[df_race_decision['race']==0]['decision_pred_with_y_pred']\n",
    "print('WHITE wihtout Y_pred')\n",
    "report_stas(D_test_white, D_test_pred_white)\n",
    "print('\\nWHITE whit Y_pred')\n",
    "report_stas(D_test_white, D_test_pred_wy_white)\n",
    "\n",
    "\n",
    "D_test_non_white = df_race_decision[df_race_decision['race']==1]['decision']\n",
    "D_test_pred_non_white = df_race_decision[df_race_decision['race']==1]['decision_pred']\n",
    "D_test_pred_wy_non_white = df_race_decision[df_race_decision['race']==1]['decision_pred_with_y_pred']\n",
    "print('\\nNON WHITE wihtout Y_pred')\n",
    "report_stas(D_test_non_white, D_test_pred_non_white)\n",
    "print('\\nNON WHITE whit Y_pred')\n",
    "report_stas(D_test_non_white, D_test_pred_wy_non_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will find the the group-specific thresholds for both models of judges' decision (with/without Yhat) that obtain statistical parity.\n",
    "\n",
    "You can use a custom classifier `threshold` for the decision with this type of code snippet: `decisions = (logit.predict_proba(X) >= threshold).astype(int)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforcing Statistical Parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model without Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_pred = (model_D.predict_proba(X) >= 0.6).astype(int)\n",
    "D_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.24489795918367346 which achieves  0.005499339099943157 % difference in accuracy.\n"
     ]
    }
   ],
   "source": [
    "##Find the largest and lowest thresholds to enforce statistical parity\n",
    "##hint: build a recursive function to find the probability threshold that minimizes \n",
    "## the difference between the predicted outcomes for whites and non whites\n",
    "import numpy as np\n",
    "\n",
    "best_loss = 1000000000000000\n",
    "best_threshold = None\n",
    "\n",
    "for threshold in np.linspace(0, 1, num=50):\n",
    "    D_pred = (model_D.predict_proba(X) >= threshold).astype(int)[:,1]\n",
    "\n",
    "    df_race_decision_calib = pd.DataFrame(NW)\n",
    "    df_race_decision_calib['decision'] = D\n",
    "    df_race_decision_calib['decision_pred'] = D_pred\n",
    "\n",
    "    D_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision']\n",
    "    D_pred_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision_pred']\n",
    "    D_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision']\n",
    "    D_pred_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision_pred']\n",
    "    \n",
    "    loss = abs(accuracy_score(D_white, D_pred_white) - accuracy_score(D_non_white, D_pred_non_white))\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"The best threshold is \",best_threshold, \"which achieves \", best_loss, \"% difference in accuracy.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.0 which achieves  0.014321327553026064 % difference in accuracy.\n"
     ]
    }
   ],
   "source": [
    "##Find the largest and lowest thresholds to enforce statistical parity\n",
    "##hint: build a recursive function to find the probability threshold that minimizes \n",
    "## the difference between the predicted outcomes for whites and non whites\n",
    "\n",
    "best_loss = 1000000000000000\n",
    "best_threshold = None\n",
    "\n",
    "for threshold in np.linspace(0, 1, num=100):\n",
    "    D_pred = (model_D.predict_proba(X) >= threshold).astype(int)[:,1]\n",
    "\n",
    "    df_race_decision_calib = pd.DataFrame(NW)\n",
    "    df_race_decision_calib['decision'] = D\n",
    "    df_race_decision_calib['decision_pred_wy'] = D_pred_with_y_pred\n",
    "\n",
    "    D_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision']\n",
    "    D_pred_wy_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision_pred_wy']\n",
    "    D_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision']\n",
    "    D_pred_wy_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision_pred_wy']\n",
    "    \n",
    "    loss = abs(accuracy_score(D_white, D_pred_wy_white) - accuracy_score(D_non_white, D_pred_wy_non_white))\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"The best threshold is \",best_threshold, \"which achieves \", best_loss, \"% difference in accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 1: More Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains error rate balance (equality of recalls for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.0 which achieves  0.0 % difference in recall.\n",
      "The best threshold is  0.0 which achieves  0.0 % difference in recall.\n"
     ]
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "def calibrate_recall(uncalibrated_model, dataX):\n",
    "    best_loss = 1000000000000000\n",
    "    best_threshold = None\n",
    "\n",
    "    for threshold in np.linspace(0, 1, num=50):\n",
    "        D_pred = (uncalibrated_model.predict_proba(dataX) >= threshold).astype(int)[:,1]\n",
    "\n",
    "        df_race_decision_calib = pd.DataFrame(NW)\n",
    "        df_race_decision_calib['decision'] = D\n",
    "        df_race_decision_calib['decision_pred'] = D_pred\n",
    "\n",
    "        D_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision']\n",
    "        D_pred_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision_pred']\n",
    "        D_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision']\n",
    "        D_pred_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision_pred']\n",
    "        \n",
    "        loss = abs(recall_score(D_white, D_pred_white) - recall_score(D_non_white, D_pred_non_white))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(\"The best threshold is \",best_threshold, \"which achieves \", best_loss, \"% difference in recall.\")\n",
    "\n",
    "\n",
    "calibrate_recall(model_D, X)\n",
    "calibrate_recall(model_D_with_y, Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains predictive parity (equality of precisions for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.9591836734693877 which achieves  0.0 % difference in precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.9591836734693877 which achieves  0.0 % difference in precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/brj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##TODO\n",
    "def calibrate_precision(uncalibrated_model, dataX):\n",
    "    best_loss = 1000000000000000\n",
    "    best_threshold = None\n",
    "\n",
    "    for threshold in np.linspace(0, 1, num=50):\n",
    "        D_pred = (uncalibrated_model.predict_proba(dataX) >= threshold).astype(int)[:,1]\n",
    "\n",
    "        df_race_decision_calib = pd.DataFrame(NW)\n",
    "        df_race_decision_calib['decision'] = D\n",
    "        df_race_decision_calib['decision_pred'] = D_pred\n",
    "\n",
    "        D_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision']\n",
    "        D_pred_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision_pred']\n",
    "        D_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision']\n",
    "        D_pred_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision_pred']\n",
    "        \n",
    "        loss = abs(precision_score(D_white, D_pred_white) - precision_score(D_non_white, D_pred_non_white))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(\"The best threshold is \",best_threshold, \"which achieves \", best_loss, \"% difference in precision.\")\n",
    "\n",
    "\n",
    "calibrate_precision(model_D, X)\n",
    "calibrate_precision(model_D_with_y, Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold for both models (with/without Yhat) that obtains treatment equality (ratio of false positives to false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
      "/var/folders/4l/50kz2_m54d53hffxvvphv1lr0000gn/T/ipykernel_63570/1064066095.py:10: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return FP / FN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is  0.9795918367346939 which achieves  0.0 % difference in ratio of false positives to false negatives.\n",
      "The best threshold is  0.9795918367346939 which achieves  0.0 % difference in ratio of false positives to false negatives.\n"
     ]
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "\n",
    "def FPFN(Y, Y_pred):\n",
    "    cm = confusion_matrix(Y, Y_pred)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    return FP / FN\n",
    "\n",
    "def calibrate_FPFN(uncalibrated_model, dataX):\n",
    "    best_loss = 1000000000000000\n",
    "    best_threshold = None\n",
    "\n",
    "    for threshold in np.linspace(0, 1, num=50):\n",
    "        D_pred = (uncalibrated_model.predict_proba(dataX) >= threshold).astype(int)[:,1]\n",
    "\n",
    "        df_race_decision_calib = pd.DataFrame(NW)\n",
    "        df_race_decision_calib['decision'] = D\n",
    "        df_race_decision_calib['decision_pred'] = D_pred\n",
    "\n",
    "        D_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision']\n",
    "        D_pred_white = df_race_decision_calib[df_race_decision_calib['race']==0]['decision_pred']\n",
    "        D_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision']\n",
    "        D_pred_non_white = df_race_decision_calib[df_race_decision_calib['race']==1]['decision_pred']\n",
    "        \n",
    "        loss = abs(FPFN(D_white, D_pred_white) - FPFN(D_non_white, D_pred_non_white))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(\"The best threshold is \",best_threshold, \"which achieves \", best_loss, \"% difference in ratio of false positives to false negatives.\")\n",
    "\n",
    "\n",
    "calibrate_FPFN(model_D, X)\n",
    "calibrate_FPFN(model_D_with_y, Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1: the threshold at 0 for calibrating the recall is trivially right but clearly unfair.\n",
    "\n",
    "Note 2: These experiments shows how it's hvery hard to impossible to calibrate for several different fairness metric   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 2: Pre-Processing for Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress all predictors in `X` on the protected attribute `A` and produce residuals `Xtilde`. Re-do the prediction task above (predicting judges' decision) and discuss how it changes the fairness metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('brj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfffd512b5389e9d3dcf7625ef773f2ceb18044b61b4057c9b3522de66270c4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
